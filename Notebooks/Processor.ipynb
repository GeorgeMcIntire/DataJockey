{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23d7fee3",
   "metadata": {},
   "source": [
    "# Music ETL Process Notebook\n",
    "\n",
    "This code is the notebook version of the `processor.py` file which is the ETL script I use whenever I have a new batch of songs that need to processed, analyzed, and uploaded to my database.\n",
    "\n",
    "Here I annotate each step of the process with explanations of what this code does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9cef199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matchering as mg\n",
    "import json\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from io import StringIO\n",
    "import sys\n",
    "import pathlib\n",
    "\n",
    "import taglib\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import os\n",
    "from essentia.standard import MusicExtractor, YamlOutput,MetadataReader, PCA, YamlInput\n",
    "import warnings\n",
    "from zipfile import ZipFile\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab31690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import utility functions from project_tools package\n",
    "from project_tools.utils import json_opener, adapt_array, convert_array, tag_cleaner, digit2letters\n",
    "from project_tools.models import Activator, Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd16ec7",
   "metadata": {},
   "source": [
    "Since my sqlite database holds numpy arrays, which aren't a native data type, I need to register two functions `adapt_array` and `convert_array` which are used to handle the arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf77a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sqlite3.register_adapter(np.ndarray, adapt_array)\n",
    "sqlite3.register_converter(\"array\", convert_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3802ec7",
   "metadata": {},
   "source": [
    "Connect to the `jaage.db` database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "069e3e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"/Users/georgemcintire/projects/djing/jaage.db\", detect_types= sqlite3.PARSE_DECLTYPES)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837a58db",
   "metadata": {},
   "source": [
    "`Loading Dock` is the directory in my hard drive which is the staging area for newly downloaded songs.\n",
    "\n",
    "`DJ Hub` is where the original files are sent to after being processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a54012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"/Volumes/LaCie/Loading Dock/\"\n",
    "dj_hub  = \"/Volumes/LaCie/DJ Hub/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6989fec",
   "metadata": {},
   "source": [
    "Sometimes downloaded songs are packaged as zip files, so if that is the case I unzip them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0d9e0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_files = glob(load_path+\"*.zip\")\n",
    "zip_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e796a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(zip_files) > 0:\n",
    "    for z in zip_files:\n",
    "        zf = ZipFile(z)\n",
    "        zf.extractall(path=load_path)\n",
    "        shutil.move(z,dj_hub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8622ceb",
   "metadata": {},
   "source": [
    "Collect all the music files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "41a018cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_files = pathlib.Path(load_path).glob(\"*[.wav, .mp3, .aiff]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2c07c5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 files for the ETL pipeline\n"
     ]
    }
   ],
   "source": [
    "len_loading_files = len(list(loading_files))\n",
    "print(\"There are {} files for the ETL pipeline\".format(len_loading_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "efb89027",
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_files = pathlib.Path(load_path).glob(\"*[.wav, .mp3, .aiff]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6062944e",
   "metadata": {},
   "source": [
    "## Process Steps\n",
    "\n",
    "### 1. Mastering\n",
    "\n",
    "\n",
    "### 2. Essentia Features Extraction\n",
    "\n",
    "\n",
    "### 3. Effnet Embeddings and Genre Activations\n",
    "\n",
    "### 4. Style, Mood, and Genre Classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ae074f",
   "metadata": {},
   "source": [
    "### Mastering\n",
    "\n",
    "Here I use the [matchering](https://github.com/sergree/matchering) package to adjust the sound and levels of the fresh batch of songs to make them more appropriate for DJing.\n",
    "\n",
    "\n",
    "The tool works by taking the sound of an existing song and adjusts new songs on based on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "07c8a0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The song used to adjust other songs.\n",
    "ref_file = '/Volumes/LaCie/DJ Hub/Rayko - Magnetized (Rayko rework).wav'\n",
    "#The directory where all my music is stored.\n",
    "collection = \"Collection\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a20403a",
   "metadata": {},
   "source": [
    "- Loop over the new files in the `loading_files` list, \n",
    "\n",
    "- Process them using matchering, \n",
    "\n",
    "- Then move them to collection\n",
    "\n",
    "- Move original files to DJ Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5611f5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:51, 51.83s/it]\n"
     ]
    }
   ],
   "source": [
    "new_file_paths = []\n",
    "for f in tqdm(loading_files):\n",
    "    out_stem = f.stem\n",
    "    out_path = f.parent.parent/collection/f.stem\n",
    "    out_path = out_path.as_posix() +\".wav\"\n",
    "    \n",
    "    mg.process(target= f.as_posix(),\n",
    "              reference=ref_file, \n",
    "              results = [mg.pcm24(out_path)])\n",
    "    \n",
    "    load_tags = taglib.File(f.as_posix())\n",
    "    mastered_tags = taglib.File(out_path)\n",
    "    mastered_tags.tags = load_tags.tags\n",
    "    mastered_tags.save()\n",
    "    \n",
    "    new_file_paths.append(out_path)\n",
    "    \n",
    "    try:\n",
    "        shutil.move(f.as_posix(), dj_hub)\n",
    "    except:\n",
    "        print(f, \"already exists\")\n",
    "        os.remove(f.as_posix())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f2516a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e867dd5f",
   "metadata": {},
   "source": [
    "**Before I move on to the next step I head over to RekordBox (the program I use to manage my library) and upload the new batch of songs on there and edit their metadata tags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0bf93d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "570ce2cb",
   "metadata": {},
   "source": [
    "### Music Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339b0d50",
   "metadata": {},
   "source": [
    "I use essentia to extract a variety of musical features and metadata from the songs.\n",
    "\n",
    "The full description of what the `MusicExtractor` tool does can be found [here](https://essentia.upf.edu/tutorial_extractors_musicextractor.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7dedacde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copied_paths = new_file_paths[:]\n",
    "new_file_paths = []\n",
    "for i in copied_paths:\n",
    "    if os.path.exists(i):\n",
    "        new_file_paths.append(i)\n",
    "        \n",
    "len(new_file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed83a518",
   "metadata": {},
   "source": [
    "Initialize the extractor object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f5916139",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_ext = MusicExtractor(lowlevelStats=['mean', 'stdev'],\n",
    "                                    rhythmStats=['mean', 'stdev', \"max\", \"min\", \"median\"],\n",
    "                                    tonalStats=['mean', 'stdev'],\n",
    "                           mfccStats = [\"mean\", \"cov\"],\n",
    "                           gfccStats = [\"mean\", \"cov\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e452daa6",
   "metadata": {},
   "source": [
    "Iterate the new batch, extract their data, and collect it in a list called `extracted_files`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "054a1714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s][   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:13<00:00, 13.41s/it]\n"
     ]
    }
   ],
   "source": [
    "out_dir = '../temp_features/'\n",
    "extracted_files = []\n",
    "id_2_paths = {}\n",
    "\n",
    "for fil in tqdm(new_file_paths, total = len(new_file_paths)):\n",
    "    try:\n",
    "        features, _ = music_ext(fil)\n",
    "        idd = features['metadata.audio_properties.md5_encoded']\n",
    "        YamlOutput(filename= out_dir+\"features.json\", format=\"json\")(features)\n",
    "        json_data = json_opener(out_dir+\"features.json\")\n",
    "        id_2_paths[idd] = fil\n",
    "        extracted_files.append(json_data)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37904aeb",
   "metadata": {},
   "source": [
    "Convert `extracted_files` to a pandas dataframe for easier data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3fc90893",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted = pd.json_normalize(extracted_files)\n",
    "extracted.columns = extracted.columns.str.replace(\".\", \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85ad738",
   "metadata": {},
   "source": [
    "Rename the `metadata_audio_properties_md5_encoded` column to `sid`. This property serves as the unique ids for my songs, `sid` is short for song id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b99082a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted.rename(columns={\"metadata_audio_properties_md5_encoded\":\"sid\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b380430",
   "metadata": {},
   "source": [
    "Load in array of column names which are used to filter unnecessary data in the `extracted` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "435ff478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 153)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols = np.load(\"../drop_cols.pkl\", allow_pickle=True).tolist()\n",
    "extracted.drop(drop_cols, axis = 1, inplace=True, \n",
    "               errors=\"ignore\"\n",
    "              )\n",
    "extracted.set_index(\"sid\", inplace=True)\n",
    "extracted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3dd3d1",
   "metadata": {},
   "source": [
    "Separate the metadata from the whole dataset, by creating a new dataframe called `meta_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "52410de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = extracted.columns\n",
    "\n",
    "meta_cols = cols[cols.str.startswith(\"meta\")]\n",
    "non_meta_cols = cols[~cols.str.startswith(\"meta\")]\n",
    "\n",
    "meta_df = extracted[meta_cols].copy()\n",
    "extracted.drop(meta_cols, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa29c54d",
   "metadata": {},
   "source": [
    "This process right is used divide the remaining data in `extracted` into a dataframe where the values are lists and another where they are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "72e63687",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cols = extracted.columns[extracted.iloc[0].apply(lambda x:type(x)) == list]\n",
    "no_list_cols = extracted.columns[extracted.iloc[0].apply(lambda x:type(x)) != list]\n",
    "list_data = extracted[list_cols]\n",
    "no_list_data = extracted[no_list_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac11ae",
   "metadata": {},
   "source": [
    "`tag_cleaner` is used to deal with null values and empty lists in `meta_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f6c7b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = meta_df.applymap(tag_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "845746ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df.columns = meta_df.columns.str.split(\"_\").map(lambda x:x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d2ee7812",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df.rename(columns={\"name\":\"file_name\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602e52dd",
   "metadata": {},
   "source": [
    "The clean version of `meta_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5089280b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>gain</th>\n",
       "      <th>codec</th>\n",
       "      <th>file_name</th>\n",
       "      <th>album</th>\n",
       "      <th>artist</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cd25d43df8d225f17346b27bf435ee11</th>\n",
       "      <td>306.025574</td>\n",
       "      <td>-13.738892</td>\n",
       "      <td>pcm_s24le</td>\n",
       "      <td>Turn Me On.wav</td>\n",
       "      <td>Move</td>\n",
       "      <td>Demuja</td>\n",
       "      <td>2020</td>\n",
       "      <td>Turn Me On</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      length       gain      codec  \\\n",
       "sid                                                                  \n",
       "cd25d43df8d225f17346b27bf435ee11  306.025574 -13.738892  pcm_s24le   \n",
       "\n",
       "                                       file_name album  artist  date  \\\n",
       "sid                                                                    \n",
       "cd25d43df8d225f17346b27bf435ee11  Turn Me On.wav  Move  Demuja  2020   \n",
       "\n",
       "                                       title  \n",
       "sid                                           \n",
       "cd25d43df8d225f17346b27bf435ee11  Turn Me On  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8743a7d",
   "metadata": {},
   "source": [
    "Before uploading `meta_df` to the `tags` table in the db, I need to make sure the column name are aligned. I import the columns from `tags` and use that to filter `meta_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3cac5eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_cols = pd.read_sql(\"SELECT * FROM tags LIMIT 1\", con = conn).set_index('sid').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8592d9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['length', 'gain', 'codec', 'file_name', 'album', 'artist', 'date', 'title']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_cols = [i for i in meta_df.columns if i in tags_cols]\n",
    "meta_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde87b11",
   "metadata": {},
   "source": [
    "Append `meta_df` to the `tags` table in the db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a26a3a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df[meta_cols].to_sql(\"tags\", con=conn, if_exists = \"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d4d736",
   "metadata": {},
   "source": [
    "Now it's time to update the `files` table which is how I connect the song paths to their unique ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1c0a1c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.DataFrame(id_2_paths.items(), columns=[\"sid\", \"file_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "03bcbc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "files.to_sql(\"files\", con = conn, if_exists=\"append\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a101c722",
   "metadata": {},
   "source": [
    "Divide the `no_list_data` dataframe into three sections: tonal, lowlevel, rhythm. These features are explained on the essentia website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "41c25a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = no_list_data.columns\n",
    "tonal_cols = cols[cols.str.startswith(\"tonal\")]\n",
    "lowlevel_cols = cols[cols.str.startswith(\"lowlevel\")]\n",
    "rhythm_cols = cols[cols.str.startswith(\"rhyt\")]\n",
    "\n",
    "tonal_df = no_list_data[tonal_cols]\n",
    "lowlevel_df = no_list_data[lowlevel_cols]\n",
    "rhythm_df = no_list_data[rhythm_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0e91ac",
   "metadata": {},
   "source": [
    "Use those dataframes to update their corresponding tables in the db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "54044558",
   "metadata": {},
   "outputs": [],
   "source": [
    "tonal_df.to_sql(\"tonal_features\", con=conn, if_exists=\"append\")\n",
    "lowlevel_df.to_sql(\"lowlevel_features\", con=conn, if_exists=\"append\")\n",
    "rhythm_df.to_sql(\"rhythm_features\", con=conn, if_exists=\"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c40686a",
   "metadata": {},
   "source": [
    "Upload the dataframes with list values to the db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e6f46702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 87.66it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(list_cols):\n",
    "    ser = list_data[col].apply(pd.Series)\n",
    "    ser.columns = col + \"_\"+ ser.columns.astype(str)\n",
    "    ser.to_sql(col+\"_tbl\", con = conn,if_exists=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d8c43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7024ea97",
   "metadata": {},
   "source": [
    "### EffNet Embbedings and Genre Classifications\n",
    "\n",
    "I use the [discogs-effnet model](https://essentia.upf.edu/models.html#discogs-effnet) to generate Nx1280 embeddings and activation scores for 400 genres.\n",
    "\n",
    "Those embeddings are then used later on as the input data for the other classification models.\n",
    "\n",
    "The metadata on this model can be found [here](https://essentia.upf.edu/models/music-style-classification/discogs-effnet/discogs-effnet-bs64-1.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6ccdd9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2id = {v:k for k, v in id_2_paths.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98342638",
   "metadata": {},
   "source": [
    "Initialize the `Activator` which is the tool I used to preprocess the raw song data, generate the predictions and then upload them to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6d841027",
   "metadata": {},
   "outputs": [],
   "source": [
    "act = Activator(input_length=2.05, \n",
    "                model_path=\"../onnx_models/discogs-effnet-bsdynamic-1.onnx\",\n",
    "                   pathid_dict=path2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d40f623",
   "metadata": {},
   "source": [
    "Grab the columns names from the `effnet_genres` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4b830993",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcols = pd.read_sql_query(\"SELECT * FROM effnet_genres LIMIT 1 \", con = conn).columns[1:].tolist()\n",
    "# gcols[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f3219a",
   "metadata": {},
   "source": [
    "- Iterate over the new batch of songs\n",
    "\n",
    "- Generate the activations and embeddings.\n",
    "\n",
    "- Upload them to their corresponding tables in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6a0fb205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.38s/it]\n"
     ]
    }
   ],
   "source": [
    "for song in act.batch_inference():\n",
    "    with conn:\n",
    "        sid, sf, output = song\n",
    "        genre_acts = output[\"activations\"]\n",
    "        embeds = output[\"embeddings\"]\n",
    "        genre_acts = [np.expand_dims(genre_acts[:, i], 0) for i in range(400)]\n",
    "        genre_acts = pd.DataFrame(index = [sid], data = [genre_acts], columns=gcols)\n",
    "        cur.execute(\"INSERT INTO effnet_embeddings (sid, effnet_embedding) values (?,?)\", \n",
    "                    (sid, np.expand_dims(embeds,0)))\n",
    "        genre_acts.to_sql(\"effnet_genres\", con=conn, if_exists=\"append\", index=False)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d532806f",
   "metadata": {},
   "source": [
    "### Classification Head Models\n",
    "\n",
    "This section is where I use the discogs-effnet embeddings to generate predictions from a variety of music [style and mood classification models](https://essentia.upf.edu/models.html#classification-heads).\n",
    "\n",
    "These models classify attributes such as danceability, happiness, relaxedness, and more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba03606d",
   "metadata": {},
   "source": [
    "The `onnx_models` directory hosts all the downloaded models. The `json_info` subdirectory hosts all their corresponding metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991bb765",
   "metadata": {},
   "source": [
    "I collect all the models and their metadata here.\n",
    "\n",
    "I have other models but for now I'm only working with the effnet ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a117e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = sorted(glob(\"../onnx_models/*.onnx\"))\n",
    "model_infos = sorted(glob(\"../onnx_models/json_info/*.json\"))\n",
    "effnet_models = [{\"model\": model_paths[i], \n",
    "                  \"json\":model_infos[i]} for i in range(len(model_paths)) if \"effnet\" in model_paths[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "59de0bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "effnet_models = effnet_models[:2] + effnet_models[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9d839c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ids = list(path2id.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333d327b",
   "metadata": {},
   "source": [
    "- Iterate over all the models.\n",
    "\n",
    "- Generate batch inferences from them. The models are feed data queried from the database.\n",
    "\n",
    "- Upload the predictions to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b557208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 375.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed =>  approachability_2c_effnet_discogs_1_activations \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 210.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed =>  danceability_effnet_discogs_1_activations \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 214.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed =>  engagement_2c_effnet_discogs_1_activations \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 381.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed =>  genre_electronic_effnet_discogs_1_activations \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 404.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed =>  mood_acoustic_effnet_discogs_1_activations \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 328.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed =>  mood_aggressive_effnet_discogs_1_activations \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 333.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed =>  mood_happy_effnet_discogs_1_activations \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 348.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed =>  mood_party_effnet_discogs_1_activations \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for em in effnet_models:\n",
    "    cls = Classifier(em, new_ids=new_ids)\n",
    "    cls.batch_inference()\n",
    "    cls.conn.commit()\n",
    "    print(\"Completed => \", cls.table_name, \"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music",
   "language": "python",
   "name": "music"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
